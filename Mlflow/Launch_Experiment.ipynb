{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lien=\"https://minio.lab.sspcloud.fr/alimane/diffusion/TMDB_movies.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>status</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>...</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Released</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>825532764</td>\n",
       "      <td>148</td>\n",
       "      <td>False</td>\n",
       "      <td>/8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Cobb, a skilled thief who commits corporate es...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>/oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg</td>\n",
       "      <td>Your mind is the scene of the crime.</td>\n",
       "      <td>Action, Science Fiction, Adventure</td>\n",
       "      <td>Legendary Pictures, Syncopy, Warner Bros. Pict...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, French, Japanese, Swahili</td>\n",
       "      <td>rescue, mission, dream, airplane, paris, franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157336</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>32571</td>\n",
       "      <td>Released</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>701729206</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "      <td>/pbrkL804c8yAv3zBZR4QPEafpAR.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>140.241</td>\n",
       "      <td>/gEU2QniE6E77NI6lCU6MxlNBvIx.jpg</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Adventure, Drama, Science Fiction</td>\n",
       "      <td>Legendary Pictures, Syncopy, Lynda Obst Produc...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>rescue, future, spacecraft, race against time,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>30619</td>\n",
       "      <td>Released</td>\n",
       "      <td>2008-07-16</td>\n",
       "      <td>1004558444</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>/nMKdUUepR0i5zn0y1T4CsSB5chy.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Batman raises the stakes in his war on crime. ...</td>\n",
       "      <td>130.643</td>\n",
       "      <td>/qJ2tW6WMUDux911r6m7haRef0WH.jpg</td>\n",
       "      <td>Welcome to a world without rules.</td>\n",
       "      <td>Drama, Action, Crime, Thriller</td>\n",
       "      <td>DC Comics, Legendary Pictures, Syncopy, Isobel...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>joker, sadism, chaos, secret identity, crime f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>29815</td>\n",
       "      <td>Released</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>2923706026</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>/vL5LR6WdxWPjLPFRLe133jXWsh5.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>79.932</td>\n",
       "      <td>/kyeqWdyUXW608qlYkRqosgbbJyK.jpg</td>\n",
       "      <td>Enter the world of Pandora.</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "      <td>Dune Entertainment, Lightstorm Entertainment, ...</td>\n",
       "      <td>United States of America, United Kingdom</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>future, society, culture clash, space travel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24428</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.710</td>\n",
       "      <td>29166</td>\n",
       "      <td>Released</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>1518815515</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>When an unexpected enemy emerges and threatens...</td>\n",
       "      <td>98.082</td>\n",
       "      <td>/RYMX2wcKCBAr24UyPD7xwmjaTn.jpg</td>\n",
       "      <td>Some assembly required.</td>\n",
       "      <td>Science Fiction, Action, Adventure</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English, Hindi, Russian</td>\n",
       "      <td>new york city, superhero, shield, based on com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032327</th>\n",
       "      <td>681663</td>\n",
       "      <td>The Best of Bosom Buddies</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>2003-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>The Best of Bosom Buddies</td>\n",
       "      <td>This collection stars the hottest super-titted...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>/4LelSgFqmJWV9g2JdoZzllo0wz4.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Score</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032328</th>\n",
       "      <td>681664</td>\n",
       "      <td>Beautiful New Faces 3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>2014-10-03</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Beautiful New Faces 3</td>\n",
       "      <td>These are the best new girls in adult. Each on...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>/r30wMhdaVhug5pkofvbacTj0JCt.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Skow for Girlfriends Films</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032329</th>\n",
       "      <td>681665</td>\n",
       "      <td>Cannibal Cheerleader Camp</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>2008-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Cannibal Cheerleader Camp</td>\n",
       "      <td>Something in the woods is growing tired of fee...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>/mjHPpFdWG53BvoTfzF5uSH5buBU.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032330</th>\n",
       "      <td>681667</td>\n",
       "      <td>Beautiful New Faces 4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Beautiful New Faces 4</td>\n",
       "      <td>These are the best new girls in adult. Each on...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>/ymIl5IWMRVCB94Fnf0XD6tEVTHt.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Skow for Girlfriends Films</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032331</th>\n",
       "      <td>1284323</td>\n",
       "      <td>Karmika Kallanalla</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Released</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Karmika Kallanalla</td>\n",
       "      <td>Mohan, a factory worker, tries to give his bro...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Kannada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1032332 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                      title  vote_average  vote_count  \\\n",
       "0          27205                  Inception         8.364       34495   \n",
       "1         157336               Interstellar         8.417       32571   \n",
       "2            155            The Dark Knight         8.512       30619   \n",
       "3          19995                     Avatar         7.573       29815   \n",
       "4          24428               The Avengers         7.710       29166   \n",
       "...          ...                        ...           ...         ...   \n",
       "1032327   681663  The Best of Bosom Buddies         0.000           0   \n",
       "1032328   681664      Beautiful New Faces 3         0.000           0   \n",
       "1032329   681665  Cannibal Cheerleader Camp         0.000           0   \n",
       "1032330   681667      Beautiful New Faces 4         0.000           0   \n",
       "1032331  1284323         Karmika Kallanalla         0.000           0   \n",
       "\n",
       "           status release_date     revenue  runtime  adult  \\\n",
       "0        Released   2010-07-15   825532764      148  False   \n",
       "1        Released   2014-11-05   701729206      169  False   \n",
       "2        Released   2008-07-16  1004558444      152  False   \n",
       "3        Released   2009-12-15  2923706026      162  False   \n",
       "4        Released   2012-04-25  1518815515      143  False   \n",
       "...           ...          ...         ...      ...    ...   \n",
       "1032327  Released   2003-08-13           0      115   True   \n",
       "1032328  Released   2014-10-03           0      183   True   \n",
       "1032329  Released   2008-11-01           0       18  False   \n",
       "1032330  Released   2015-04-24           0      199   True   \n",
       "1032331  Released         None           0      155  False   \n",
       "\n",
       "                            backdrop_path  ...             original_title  \\\n",
       "0        /8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg  ...                  Inception   \n",
       "1        /pbrkL804c8yAv3zBZR4QPEafpAR.jpg  ...               Interstellar   \n",
       "2        /nMKdUUepR0i5zn0y1T4CsSB5chy.jpg  ...            The Dark Knight   \n",
       "3        /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg  ...                     Avatar   \n",
       "4        /9BBTo63ANSmhC4e6r62OJFuK2GL.jpg  ...               The Avengers   \n",
       "...                                   ...  ...                        ...   \n",
       "1032327                              None  ...  The Best of Bosom Buddies   \n",
       "1032328                              None  ...      Beautiful New Faces 3   \n",
       "1032329                              None  ...  Cannibal Cheerleader Camp   \n",
       "1032330                              None  ...      Beautiful New Faces 4   \n",
       "1032331                              None  ...         Karmika Kallanalla   \n",
       "\n",
       "                                                  overview popularity  \\\n",
       "0        Cobb, a skilled thief who commits corporate es...     83.952   \n",
       "1        The adventures of a group of explorers who mak...    140.241   \n",
       "2        Batman raises the stakes in his war on crime. ...    130.643   \n",
       "3        In the 22nd century, a paraplegic Marine is di...     79.932   \n",
       "4        When an unexpected enemy emerges and threatens...     98.082   \n",
       "...                                                    ...        ...   \n",
       "1032327  This collection stars the hottest super-titted...      0.600   \n",
       "1032328  These are the best new girls in adult. Each on...      0.600   \n",
       "1032329  Something in the woods is growing tired of fee...      0.600   \n",
       "1032330  These are the best new girls in adult. Each on...      0.600   \n",
       "1032331  Mohan, a factory worker, tries to give his bro...      0.000   \n",
       "\n",
       "                              poster_path  \\\n",
       "0        /oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg   \n",
       "1        /gEU2QniE6E77NI6lCU6MxlNBvIx.jpg   \n",
       "2        /qJ2tW6WMUDux911r6m7haRef0WH.jpg   \n",
       "3        /kyeqWdyUXW608qlYkRqosgbbJyK.jpg   \n",
       "4         /RYMX2wcKCBAr24UyPD7xwmjaTn.jpg   \n",
       "...                                   ...   \n",
       "1032327  /4LelSgFqmJWV9g2JdoZzllo0wz4.jpg   \n",
       "1032328  /r30wMhdaVhug5pkofvbacTj0JCt.jpg   \n",
       "1032329  /mjHPpFdWG53BvoTfzF5uSH5buBU.jpg   \n",
       "1032330  /ymIl5IWMRVCB94Fnf0XD6tEVTHt.jpg   \n",
       "1032331                              None   \n",
       "\n",
       "                                                   tagline  \\\n",
       "0                     Your mind is the scene of the crime.   \n",
       "1        Mankind was born on Earth. It was never meant ...   \n",
       "2                        Welcome to a world without rules.   \n",
       "3                              Enter the world of Pandora.   \n",
       "4                                  Some assembly required.   \n",
       "...                                                    ...   \n",
       "1032327                                               None   \n",
       "1032328                                               None   \n",
       "1032329                                               None   \n",
       "1032330                                               None   \n",
       "1032331                                               None   \n",
       "\n",
       "                                              genres  \\\n",
       "0                 Action, Science Fiction, Adventure   \n",
       "1                  Adventure, Drama, Science Fiction   \n",
       "2                     Drama, Action, Crime, Thriller   \n",
       "3        Action, Adventure, Fantasy, Science Fiction   \n",
       "4                 Science Fiction, Action, Adventure   \n",
       "...                                              ...   \n",
       "1032327                                         None   \n",
       "1032328                                         None   \n",
       "1032329                                         None   \n",
       "1032330                                         None   \n",
       "1032331                                         None   \n",
       "\n",
       "                                      production_companies  \\\n",
       "0        Legendary Pictures, Syncopy, Warner Bros. Pict...   \n",
       "1        Legendary Pictures, Syncopy, Lynda Obst Produc...   \n",
       "2        DC Comics, Legendary Pictures, Syncopy, Isobel...   \n",
       "3        Dune Entertainment, Lightstorm Entertainment, ...   \n",
       "4                                           Marvel Studios   \n",
       "...                                                    ...   \n",
       "1032327                                              Score   \n",
       "1032328                         Skow for Girlfriends Films   \n",
       "1032329                                               None   \n",
       "1032330                         Skow for Girlfriends Films   \n",
       "1032331                                               None   \n",
       "\n",
       "                             production_countries  \\\n",
       "0        United Kingdom, United States of America   \n",
       "1        United Kingdom, United States of America   \n",
       "2        United Kingdom, United States of America   \n",
       "3        United States of America, United Kingdom   \n",
       "4                        United States of America   \n",
       "...                                           ...   \n",
       "1032327                  United States of America   \n",
       "1032328                  United States of America   \n",
       "1032329                                      None   \n",
       "1032330                  United States of America   \n",
       "1032331                                      None   \n",
       "\n",
       "                           spoken_languages  \\\n",
       "0        English, French, Japanese, Swahili   \n",
       "1                                   English   \n",
       "2                         English, Mandarin   \n",
       "3                          English, Spanish   \n",
       "4                   English, Hindi, Russian   \n",
       "...                                     ...   \n",
       "1032327                                None   \n",
       "1032328                             English   \n",
       "1032329                                None   \n",
       "1032330                             English   \n",
       "1032331                             Kannada   \n",
       "\n",
       "                                                  keywords  \n",
       "0        rescue, mission, dream, airplane, paris, franc...  \n",
       "1        rescue, future, spacecraft, race against time,...  \n",
       "2        joker, sadism, chaos, secret identity, crime f...  \n",
       "3        future, society, culture clash, space travel, ...  \n",
       "4        new york city, superhero, shield, based on com...  \n",
       "...                                                    ...  \n",
       "1032327                                               None  \n",
       "1032328                                               None  \n",
       "1032329                                               None  \n",
       "1032330                                               None  \n",
       "1032331                                               None  \n",
       "\n",
       "[1032332 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_part = pd.read_parquet(lien)\n",
    "restored_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.train_models\n",
    "#model2=train5.XGBRegressorWrapper(df,with_duration=True)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.train_models as train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:892: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  .groupby(level=0, axis=1)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:736: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:736: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/home/onyxia/work/cine-insights/src/features/preprocess_train_data.py:739: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x.shape, y.shape ) \n",
      "\n",
      " Pour le train : (9014, 29) (9014,) \n",
      "\n",
      " Pour le test : (2404, 29) (2404,) \n",
      "\n",
      " Pour la validation : (601, 29) (601,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models=train_models.XGBRegressorWrapper(restored_part,with_duration=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.03,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.05,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 500,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 1000,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.7},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'learning_rate': 0.07,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 2800,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'subsample': 0.9}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.param_Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Mlflow_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv(\"X.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "API request to https://user-odione-mlflow.user.lab.sspcloud.fr/api/2.0/mlflow-artifacts/artifacts/19/b0710f01b26c49f18a6850bdef0ead4c/artifacts/ct_data_transformers/ct_data_transformer.pkl failed with exception HTTPSConnectionPool(host='user-odione-mlflow.user.lab.sspcloud.fr', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/19/b0710f01b26c49f18a6850bdef0ead4c/artifacts/ct_data_transformers/ct_data_transformer.pkl (Caused by ResponseError('too many 500 error responses'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;31mResponseError\u001b[0m: too many 500 error responses",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/urllib3/connectionpool.py:948\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    947\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRetry: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url)\n\u001b[0;32m--> 948\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    949\u001b[0m         method,\n\u001b[1;32m    950\u001b[0m         url,\n\u001b[1;32m    951\u001b[0m         body,\n\u001b[1;32m    952\u001b[0m         headers,\n\u001b[1;32m    953\u001b[0m         retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    954\u001b[0m         redirect\u001b[39m=\u001b[39;49mredirect,\n\u001b[1;32m    955\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49massert_same_host,\n\u001b[1;32m    956\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    957\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    958\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    959\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    960\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    961\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    962\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    963\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/urllib3/connectionpool.py:948\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    947\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRetry: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url)\n\u001b[0;32m--> 948\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    949\u001b[0m         method,\n\u001b[1;32m    950\u001b[0m         url,\n\u001b[1;32m    951\u001b[0m         body,\n\u001b[1;32m    952\u001b[0m         headers,\n\u001b[1;32m    953\u001b[0m         retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    954\u001b[0m         redirect\u001b[39m=\u001b[39;49mredirect,\n\u001b[1;32m    955\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49massert_same_host,\n\u001b[1;32m    956\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    957\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    958\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    959\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    960\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    961\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    962\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    963\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "    \u001b[0;31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 948 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/urllib3/connectionpool.py:948\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    947\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRetry: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url)\n\u001b[0;32m--> 948\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    949\u001b[0m         method,\n\u001b[1;32m    950\u001b[0m         url,\n\u001b[1;32m    951\u001b[0m         body,\n\u001b[1;32m    952\u001b[0m         headers,\n\u001b[1;32m    953\u001b[0m         retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    954\u001b[0m         redirect\u001b[39m=\u001b[39;49mredirect,\n\u001b[1;32m    955\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49massert_same_host,\n\u001b[1;32m    956\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    957\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    958\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    959\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    960\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    961\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    962\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    963\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/urllib3/connectionpool.py:938\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 938\u001b[0m     retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(method, url, response\u001b[39m=\u001b[39;49mresponse, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    939\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError:\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='user-odione-mlflow.user.lab.sspcloud.fr', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/19/b0710f01b26c49f18a6850bdef0ead4c/artifacts/ct_data_transformers/ct_data_transformer.pkl (Caused by ResponseError('too many 500 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:128\u001b[0m, in \u001b[0;36mhttp_request\u001b[0;34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_http_response_with_retries(\n\u001b[1;32m    129\u001b[0m         method,\n\u001b[1;32m    130\u001b[0m         url,\n\u001b[1;32m    131\u001b[0m         max_retries,\n\u001b[1;32m    132\u001b[0m         backoff_factor,\n\u001b[1;32m    133\u001b[0m         backoff_jitter,\n\u001b[1;32m    134\u001b[0m         retry_codes,\n\u001b[1;32m    135\u001b[0m         raise_on_status,\n\u001b[1;32m    136\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    137\u001b[0m         verify\u001b[39m=\u001b[39;49mhost_creds\u001b[39m.\u001b[39;49mverify,\n\u001b[1;32m    138\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    139\u001b[0m         respect_retry_after_header\u001b[39m=\u001b[39;49mrespect_retry_after_header,\n\u001b[1;32m    140\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m to:\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/mlflow/utils/request_utils.py:228\u001b[0m, in \u001b[0;36m_get_http_response_with_retries\u001b[0;34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m allow_redirects \u001b[39m=\u001b[39m env_value \u001b[39mif\u001b[39;00m allow_redirects \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m allow_redirects\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method, url, allow_redirects\u001b[39m=\u001b[39;49mallow_redirects, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/requests/adapters.py:510\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ResponseError):\n\u001b[0;32m--> 510\u001b[0m     \u001b[39mraise\u001b[39;00m RetryError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _ProxyError):\n",
      "\u001b[0;31mRetryError\u001b[0m: HTTPSConnectionPool(host='user-odione-mlflow.user.lab.sspcloud.fr', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/19/b0710f01b26c49f18a6850bdef0ead4c/artifacts/ct_data_transformers/ct_data_transformer.pkl (Caused by ResponseError('too many 500 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/cine-insights/Mlflow/Launch_Experiment.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://user-odione-952209-0.user.lab.sspcloud.fr/home/onyxia/work/cine-insights/Mlflow/Launch_Experiment.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m Mlflow_log\u001b[39m.\u001b[39;49mmlflow_fun(models,\u001b[39m\"\u001b[39;49m\u001b[39mExperiment1:sur tous les Donnees\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m1\u001b[39;49m,X)\n",
      "File \u001b[0;32m~/work/cine-insights/Mlflow/Mlflow_log.py:38\u001b[0m, in \u001b[0;36mmlflow_fun\u001b[0;34m(gmodel, experiment_name, num_appli, evaluation_data)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mct_data_transformer.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     37\u001b[0m     pickle\u001b[39m.\u001b[39mdump(gmodel\u001b[39m.\u001b[39mct_data_transformer, f)\n\u001b[0;32m---> 38\u001b[0m mlflow\u001b[39m.\u001b[39;49mlog_artifact(\u001b[39m\"\u001b[39;49m\u001b[39mct_data_transformer.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m, artifact_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mct_data_transformers\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m idx, params \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(grid_params) :\n\u001b[1;32m     41\u001b[0m     run_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrun_\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/mlflow/tracking/fluent.py:1058\u001b[0m, in \u001b[0;36mlog_artifact\u001b[0;34m(local_path, artifact_path, run_id)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[39mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[39mactive, this method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[39m            mlflow.log_artifact(path)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m run_id \u001b[39m=\u001b[39m run_id \u001b[39mor\u001b[39;00m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m-> 1058\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_artifact(run_id, local_path, artifact_path)\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/mlflow/tracking/client.py:1194\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifact\u001b[39m(\u001b[39mself\u001b[39m, run_id, local_path, artifact_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Write a local file or directory to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[1;32m   1158\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \n\u001b[1;32m   1193\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_artifact(run_id, local_path, artifact_path)\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:560\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    558\u001b[0m     artifact_repo\u001b[39m.\u001b[39mlog_artifacts(local_path, path_name)\n\u001b[1;32m    559\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     artifact_repo\u001b[39m.\u001b[39;49mlog_artifact(local_path, artifact_path)\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/mlflow/store/artifact/http_artifact_repo.py:63\u001b[0m, in \u001b[0;36mHttpArtifactRepository.log_artifact\u001b[0;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m: mime_type}\n\u001b[1;32m     62\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(local_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 63\u001b[0m     resp \u001b[39m=\u001b[39m http_request(\n\u001b[1;32m     64\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_host_creds, endpoint, \u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m, data\u001b[39m=\u001b[39;49mf, extra_headers\u001b[39m=\u001b[39;49mextra_headers\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m     augmented_raise_for_status(resp)\n",
      "File \u001b[0;32m~/work/BOX_28_04_env/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:151\u001b[0m, in \u001b[0;36mhttp_request\u001b[0;34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidUrlException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid url: \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39miu\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 151\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m failed with exception \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mMlflowException\u001b[0m: API request to https://user-odione-mlflow.user.lab.sspcloud.fr/api/2.0/mlflow-artifacts/artifacts/19/b0710f01b26c49f18a6850bdef0ead4c/artifacts/ct_data_transformers/ct_data_transformer.pkl failed with exception HTTPSConnectionPool(host='user-odione-mlflow.user.lab.sspcloud.fr', port=443): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/19/b0710f01b26c49f18a6850bdef0ead4c/artifacts/ct_data_transformers/ct_data_transformer.pkl (Caused by ResponseError('too many 500 error responses'))"
     ]
    }
   ],
   "source": [
    "Mlflow_log.mlflow_fun(models,\"Experiment1:sur tous les Donnees\",1,X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nom_de_votre_environnement",
   "language": "python",
   "name": "nom_de_votre_environnement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

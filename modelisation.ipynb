{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850128cd-93a4-4175-9cb3-1e9ffc18d1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /opt/mamba/lib/python3.10/site-packages (from category_encoders) (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/mamba/lib/python3.10/site-packages (from category_encoders) (1.9.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/mamba/lib/python3.10/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/mamba/lib/python3.10/site-packages (from category_encoders) (0.13.5)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/mamba/lib/python3.10/site-packages (from category_encoders) (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/mamba/lib/python3.10/site-packages (from category_encoders) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2022.6)\n",
      "Requirement already satisfied: six in /opt/mamba/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/mamba/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/mamba/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/mamba/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/mamba/lib/python3.10/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.9)\n",
      "Installing collected packages: category_encoders\n",
      "Successfully installed category_encoders-2.5.1.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec8c5833-f522-4ca4-a15b-05fec4ae18ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'country_to_continent' from 'src.utils' (/home/onyxia/work/Projet-Python/src/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import librairies.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# local functions.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     extract_only_names, \n\u001b[1;32m      4\u001b[0m     select_first_element,\n\u001b[1;32m      5\u001b[0m     country_to_continent\n\u001b[1;32m      6\u001b[0m )  \n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'country_to_continent' from 'src.utils' (/home/onyxia/work/Projet-Python/src/utils.py)"
     ]
    }
   ],
   "source": [
    "# Import librairies.\n",
    "from src.utils import (  # local functions.\n",
    "    extract_only_names, \n",
    "    select_first_element,\n",
    "    country_to_continent\n",
    ")  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve, validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec711e-f80c-4fb5-8ded-567adbf8180d",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449cd66-8135-42c0-a04e-16a7563cd380",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb847d8-3e6c-4ccc-9800-e05b0c43e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dimension : (10000, 25)\n",
      "Dimension after restriction: (4974, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>237000000</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>3424.983</td>\n",
       "      <td>[{'id': 25, 'logo_path': '/qZCc1lty5FzX30aOCVR...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>162</td>\n",
       "      <td>7.542</td>\n",
       "      <td>27004</td>\n",
       "      <td>2920357254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  release_date     budget                                             genres  \\\n",
       "0   2009-12-15  237000000  [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   \n",
       "\n",
       "   popularity                               production_companies  \\\n",
       "0    3424.983  [{'id': 25, 'logo_path': '/qZCc1lty5FzX30aOCVR...   \n",
       "\n",
       "                                production_countries  runtime  vote_average  \\\n",
       "0  [{'iso_3166_1': 'US', 'name': 'United States o...      162         7.542   \n",
       "\n",
       "   vote_count     revenue  \n",
       "0       27004  2920357254  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the movie data into a pandas DataFrame.\n",
    "movies_df = pd.read_pickle(\"./data/movies_tmdb.pkl\")\n",
    "print(\"Initial dimension :\", movies_df.shape)\n",
    "\n",
    "# Conserver seulement les lignes avec des buget et revenue non nuls.\n",
    "movies_df = movies_df.query('budget > 0 and revenue > 0')\n",
    "print(\"Dimension after restriction:\", movies_df.shape)\n",
    "\n",
    "# Restrictions des colonnes.\n",
    "columns = [\n",
    "    \"release_date\", \"budget\", \"genres\", \"popularity\", \n",
    "    \"production_companies\", \"production_countries\", \"runtime\", \n",
    "    \"vote_average\", \"vote_count\", \"revenue\"\n",
    "]\n",
    "movies_df = movies_df[columns]\n",
    "\n",
    "movies_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a22af-b096-4d4a-ba73-38a259a96463",
   "metadata": {},
   "source": [
    "## Pré-traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a53067-7204-42a9-8e9c-9a610fec6b56",
   "metadata": {},
   "source": [
    "### Traitements généraux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ce44cd-1c4b-4291-b72e-10ffdf10abf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Action, Adventure, Fantasy, Science Fiction]</td>\n",
       "      <td>[United States of America, United Kingdom]</td>\n",
       "      <td>[20th Century Fox, Ingenious Media, Dune Enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Family, Comedy, Fantasy]</td>\n",
       "      <td>[Germany, United States of America]</td>\n",
       "      <td>[Imagine Entertainment, Universal Pictures, LU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          genres  \\\n",
       "0  [Action, Adventure, Fantasy, Science Fiction]   \n",
       "3                      [Family, Comedy, Fantasy]   \n",
       "\n",
       "                         production_countries  \\\n",
       "0  [United States of America, United Kingdom]   \n",
       "3         [Germany, United States of America]   \n",
       "\n",
       "                                production_companies  \n",
       "0  [20th Century Fox, Ingenious Media, Dune Enter...  \n",
       "3  [Imagine Entertainment, Universal Pictures, LU...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listes des colonnes à traiter. \n",
    "colnames = [\"genres\", \"production_countries\", \"production_companies\"]\n",
    "\n",
    "# Appliquer les fonctions de néttoyage.\n",
    "for colname in colnames:\n",
    "    try:\n",
    "        # Extraire uniquement les noms.\n",
    "        movies_df[colname] = movies_df[colname].apply(extract_only_names)\n",
    "        # Remplacer les listes vides par `numpy.nan`.\n",
    "        movies_df[colname] = movies_df[colname].apply(lambda x: np.nan if not x else x)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "movies_df[colnames].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58e49ce-433c-446d-a95d-7e6516850e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "release_date            0\n",
       "budget                  0\n",
       "genres                  1\n",
       "popularity              0\n",
       "production_companies    8\n",
       "production_countries    6\n",
       "runtime                 0\n",
       "vote_average            0\n",
       "vote_count              0\n",
       "revenue                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values.\n",
    "movies_df.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3535456-d120-4b6c-bc59-d5a5d5b05c09",
   "metadata": {},
   "source": [
    "* Peu de valeurs manquantes par rapport à la taille initiale. Nous allons les supprimers ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e241bcc-0f69-49c4-b215-bd2ca95e280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les valeurs manquantesDelete missing values.\n",
    "movies_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ef646-7870-4538-9730-b81186d1a1b9",
   "metadata": {},
   "source": [
    "### Traitements spécifiques à la modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b884633-8be9-4b39-a1ab-248f0b520d07",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **`genres`, `production_countries`, `production_companies`** \n",
    "\n",
    "1. **Extraction des attributs principaux.** : Au premier abord, nous allons considérer uniquement les attributs principaux pour les le genre, la production et les pays de chaque film, de sorte que nous extrayons le premier genre de la liste et l'utilisons comme caractéristique catégorielle. Nous utiliserons ensuite l'encodage à un coup ou l'encodage par étiquette pour représenter le genre primaire sous forme de valeur numérique dans la suite de la modélisation.\n",
    "\n",
    "2. **Vectorisation suivi d'encodage**: Dans un second temps, nous pourrions tester la performance des modèles en utilisant les opérations de vectorisation sur ces variables catégorielles à modalité multiples. D'abord, on identifie la liste de tous les attributs unitaires qu'on ordonne. Un attribut unitaire est une modalité élémentaire. Le principe étant d'associer à chaque attribut unitaire une valeur entière. Ensuite, chaque modalité est représentée à l'aide d'un vecteur ordonnée dont la taille est le nombre d'attributs unitaires, et dont le k-ième élément indique la présence ou non de l'attribut numéro k. Par exemple, si on a :\n",
    "|genres              |\n",
    "|--------------------|\n",
    "|[\"Action\", \"Family\"]|\n",
    "|[\"Adventure\"]|\n",
    "\n",
    "Les valeurs unitaires sont \"Action\", \"Family\" et \"Adventure\". Considérons l'ordre arbitraire (alphabétique): (\"Action\", \"Adventure\", \"Family\"). Alors la colonne `genres` sera représentée par:\n",
    "|genres               |\n",
    "|--------------------|\n",
    "|(1, 0, 1)|\n",
    "|(0, 1, 0)|\n",
    "\n",
    "```python\n",
    "#########################\n",
    "##### Vectorisation #####\n",
    "#########################\n",
    "\n",
    "# Copier les donnees.\n",
    "df = movies_df.copy()\n",
    "\n",
    "# Identifier les valeurs unique dans la colonne genre. \n",
    "genres = df['genres'].apply(pd.Series).stack().unique()\n",
    "\n",
    "# Créer une correspondance de genre à entier.\n",
    "genre_map = {genre: i for i, genre in enumerate(genres)}\n",
    "\n",
    "# Remplacer les genres par leur valeur entières.\n",
    "df['genres'] = df['genres'].apply(lambda x: [genre_map[g] for g in x])\n",
    "\n",
    "# Convertir la colonne genre en une matrix dense/\n",
    "genres_matrix = pd.get_dummies(df['genres'].apply(pd.Series).stack()).groupby(level=0).apply(max)\n",
    "\n",
    "# Ajouter la matrice au dataframe.\n",
    "df = pd.concat([df, genres_matrix], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a12a2c-0e44-4d81-87cb-31cabb2b9e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genres\n",
      "production_countries\n",
      "production_companies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>20th Century Fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Family</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Imagine Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Walt Disney Pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Action</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>DreamWorks Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Orion Pictures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      genres      production_countries   production_companies\n",
       "0     Action  United States of America       20th Century Fox\n",
       "3     Family                   Germany  Imagine Entertainment\n",
       "5  Adventure            United Kingdom   Walt Disney Pictures\n",
       "6     Action  United States of America   DreamWorks Animation\n",
       "8     Comedy  United States of America         Orion Pictures"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "### Extraction des attributs principaux.###\n",
    "###########################################\n",
    "\n",
    "for colname in colnames:\n",
    "    print(colname)\n",
    "    movies_df[colname] = movies_df[colname].apply(select_first_element)\n",
    "    \n",
    "movies_df[colnames].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125510a-b652-473e-8e68-278c5257f473",
   "metadata": {},
   "source": [
    "#### **`Release date`** \n",
    "\n",
    "Nous avons réfléchi à plusieurs façons de gérer ces caractéristiques pour notre modélisation. Parmi celles-ci :\n",
    "\n",
    "1. Utiliser les dates **tel quel**. Cela est intéressant car on conserverais toute l'information mais impliquerait trop de catégories à inclure et expliquerait la matrice des caractéristiques pour les modèles qui ont besoin d'un encodage catégoriel. \n",
    "\n",
    "2. **Regrouper les dates** dans des catégories, telles que \"récent\", \"moyen\" et \"ancien\", en fonction de la date de sortie, puis utiliser ces catégories comme une caractéristique catégorielle dans notre modèle. Nous ne souffrons plus du problème de cardinalité élevée. Néanmoins, il est clair, d'après l'analyse descriptive, que les recettes du box-office ont augmenté au fil des ans et que cette tendance se poursuit. \n",
    "\n",
    "3. **Extraire les caractéristiques de la date**: la troisième option consiste à extraire des caractéristiques de la colonne `release_date`, telles que l'année, le mois et le jour. On peut ensuite utiliser ces caractéristiques comme données d'entrée de le modèle d'apprentissage. Cela pourrait être intéressant si l'on pense que par exemple, le mois ou le jour de sortie a un impact. Cette dernière hypothèse paraît très peu plausible, encore moins à long-terme. \n",
    "\n",
    "- Finalement, nous avons décidé d'écarter cette variable dans le cas de notre étude. Nous pensons qu'elle pourrait être mieux exploitée par une analyse de série temporelle qui étudie des saisonnalités (cycle) de réussite, éventuellement désagrégé par pays de production (panel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cd7bd0-fc1e-4c07-a232-7d249d5aad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer la date de sortie.\n",
    "movies_df.drop(columns=[\"release_date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831ce74-b2b5-40d2-a955-8c762e0b5834",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Variables numériques à grande variabilités\n",
    "\n",
    "Les films ont des chiffres d'affaires (`revenue`) et `budget` très élévé. Ainsi, afin de réduire l'influence des valeurs extrêmes et améliorer la linéarité du modèle (utile pour la régression linéaire surtout), nous utiliserons le logarithme. En effet, la fonction logarithme permet de réduire l'influence des valeurs extrêmes sur le modèle, car elle \"étale\" les valeurs sur une plage plus large. Cela peut être utile si vous avez des valeurs de chiffre d'affaires très élevées ou très faibles qui pourraient autrement perturber le modèle. D'autre part, si la relation entre les features et la cible n'est pas linéaire, utiliser la fonction log sur la cible peut aider à améliorer la linéarité et à rendre le modèle plus facile à interpréter. Enfin, quand on utilise log sur la cible, cela permet de facilement comparer les performances de notre modèle avec d'autres modèles en utilisant des métriques comme l'erreur absolue moyenne (MAE), ou le coefficient de détermination (R2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b82e9d6-ad8f-4a11-9e08-768ac588d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le logarithme du budget et du revenue.\n",
    "movies_df[\"logbudget\"] = np.log(movies_df[\"budget\"]) \n",
    "movies_df[\"logrevenue\"] = np.log(movies_df[\"revenue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa4910-c6d9-4c6b-83ba-86dde04a404a",
   "metadata": {},
   "source": [
    "#### **Variables catégorielles à cardinalité faible ou élevée**\n",
    "\n",
    "La prochaine chose à laquelle nous devons faire attention, ce sont les variables catégorielles avec une **cardinalité faible ou élevée**. S'il n'y a qu'une seule catégorie dans une colonne, elle ne fournira aucune information unique à notre modèle. À l'autre extrême, les colonnes où presque chaque ligne a sa propre catégorie n'aideront pas notre modèle à identifier des tendances utiles dans les données.\n",
    "\n",
    "Jetons un coup d'œil à la cardinalité de nos caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "218169bf-89ef-4180-bc73-7a7cfbd92547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget                   598\n",
       "genres                    18\n",
       "popularity              4578\n",
       "production_companies     944\n",
       "production_countries      65\n",
       "runtime                  150\n",
       "vote_average            2330\n",
       "vote_count              2748\n",
       "revenue                 4692\n",
       "logbudget                598\n",
       "logrevenue              4692\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values.\n",
    "movies_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6129bd8-e504-4094-9af8-974eabda5fa0",
   "metadata": {},
   "source": [
    "La variable `production_companies` a trop de valeurs uniques (944 sur 5000 observations). Cela peut augmenter la dimensionnalité des données et les rendre difficiles à modéliser. Nous allons regrouper les sociétés de production dans des classes basées sur le nombre de films qu'elles ont produits (**discrétisation**). Cela aura pour conséquence de réduire le nombre de valeurs uniques et faciliter la modélisation des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d07cc5d2-2e18-48b5-a052-b61983ea5b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function.\n",
    "def number_values_cumulative(self, column, quantile):\n",
    "    return (self[column].value_counts(normalize=True).cumsum() < quantile).sum()\n",
    "# Define a method inside the DataFrame class.\n",
    "pd.DataFrame.number_values_cumulative = number_values_cumulative\n",
    "\n",
    "movies_df.number_values_cumulative(\"production_companies\", 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a8d5ebc-37f0-43fb-9b2b-700e7e30aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantile  No production_companies\n",
      "0       0.1                        1\n",
      "1       0.2                        2\n",
      "2       0.3                        4\n",
      "3       0.4                        7\n",
      "4       0.5                       12\n",
      "5       0.6                       28\n",
      "6       0.7                       65\n",
      "7       0.8                      167\n",
      "8       0.9                      447\n",
      "9       1.0                      944\n",
      "   quantile  No production_countries\n",
      "0       0.1                        0\n",
      "1       0.2                        0\n",
      "2       0.3                        0\n",
      "3       0.4                        0\n",
      "4       0.5                        0\n",
      "5       0.6                        0\n",
      "6       0.7                        1\n",
      "7       0.8                        3\n",
      "8       0.9                        7\n",
      "9       1.0                       65\n"
     ]
    }
   ],
   "source": [
    "for col in [\"production_companies\", \"production_countries\"]:\n",
    "    print(pd.DataFrame([\n",
    "        (q, movies_df.number_values_cumulative(col, q)) for q in np.linspace(0.1, 1.0, num=10)\n",
    "    ], columns=[\"quantile\", f\"No {col}\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa7726-6392-460f-b4bb-4bae8c7aa54d",
   "metadata": {},
   "source": [
    "**Remarques**\n",
    "* Douze (12) compagnies se partagent la production de 50% des films de notre jeu de données.\n",
    "* 90% des films de notre jeu de données ont été produit dans 7 pays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cc40acd-68a3-4737-ae81-d013704f56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter le nombre de films produits par chaque compagnies.\n",
    "counts = movies_df['production_companies'].value_counts()\n",
    "\n",
    "# Conserver les 12 premières compagnies. \n",
    "top_12 = counts[:12]\n",
    "\n",
    "# Créer une classification pour les autres compagnies.\n",
    "labels = [\"compagnies_g\" + str(i) for i in range(1, 5)]\n",
    "others = pd.cut(counts[12:], bins=4, labels=labels)\n",
    "\n",
    "# Concatener les 12 premières compagnies avec les autres.\n",
    "bins = pd.concat([top_12, others])\n",
    "\n",
    "# Renommer les items en utilisant le nom des compagnies au lieu de l'effectif.\n",
    "for id, (key, value) in enumerate(bins.items()):\n",
    "    if id < 12:\n",
    "        bins[key] = key\n",
    "\n",
    "# Associer les compagnies de production à leur classe respectives.\n",
    "movies_df[\"production_companies2\"] = movies_df[\"production_companies\"].map(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "453125cc-8cac-4483-b174-9cad1cccac24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Spain', 'Italy', 'India', 'China', 'Hong Kong', 'Belgium',\n",
       "       'South Korea', 'Ireland', 'Denmark', 'Mexico', 'Czech Republic',\n",
       "       'New Zealand', 'Russia', 'Argentina', 'Netherlands', 'Brazil',\n",
       "       'Bulgaria', 'South Africa', 'Switzerland', 'United Arab Emirates',\n",
       "       'Austria', 'Norway', 'Thailand', 'Sweden', 'Hungary', 'Luxembourg',\n",
       "       'Finland', 'Morocco', 'Greece', 'Poland', 'Taiwan', 'Namibia', 'Aruba',\n",
       "       'Israel', 'Slovakia', 'Romania', 'Indonesia', 'Chile', 'Iceland',\n",
       "       'Venezuela', 'Ecuador', 'Malaysia', 'Philippines', 'Belarus', 'Turkey',\n",
       "       'Estonia', 'Ghana', 'Colombia', 'Afghanistan', 'Soviet Union', 'Kuwait',\n",
       "       'Libyan Arab Jamahiriya', 'Iran', 'Singapore', 'Uruguay', 'Peru',\n",
       "       'Cambodia', 'Qatar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df[\"production_countries\"].value_counts()[7:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d30abb2-fd8b-4a2f-b2b2-8714c6814b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((\n",
    "    movies2_df.groupby(\"production_companies\")[\"revenue\"]\n",
    "    .sum().sort_values(ascending=False).cumsum() / movies2_df[\"revenue\"].sum()\n",
    ") < 0.4).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e30e06-35c7-42ee-bcbf-a8e605bd210b",
   "metadata": {},
   "source": [
    "### Partage du jeu en données d'apprentissage et données test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c1c7a-31c5-44a6-81d2-a7173da4dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset Data.\n",
    "modelcols = [\n",
    "    \"genres\", \"popularity\", \"production_companies\", \"production_countries\", \n",
    "    \"budget\", \"runtime\", \"vote_average\", \"vote_count\", \"revenue\"\n",
    "]\n",
    "movies2_df = movies_df[modelcols]\n",
    "\n",
    "# Split features and target.\n",
    "target=\"revenue\"\n",
    "X = movies2_df.drop(columns=target)\n",
    "y = movies2_df[target]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# Train-Test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299220e-857e-463c-b2e9-7af60bdeea57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Création de pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebf316-9661-4c93-a9ba-485b877a1893",
   "metadata": {},
   "source": [
    "**Pipelines**\n",
    "- [x] Dealing Missing values\n",
    "- [x] Handling Outliers\n",
    "- [x] One Hot Encoding (categorical features)\n",
    "- [x] Normalization Operations (numerical features)\n",
    "- [ ] ~Vectorization? (for features with list as values)~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4b359ddf-9bff-42e3-907c-534e75df8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter features according to their type. \n",
    "numerical_features = make_column_selector(dtype_include=np.number)\n",
    "categorical_features = make_column_selector(dtype_include=object)\n",
    "\n",
    "# Create a pipeline of transformation for each type of columns.\n",
    "## Impute missing by the median and standardize numerical features.\n",
    "numerical_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), \n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "## Impute missing by the mode and one-hot categorical features.\n",
    "categorical_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'), \n",
    "    OneHotEncoder(drop=None, handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "# Create transformer to apply pipeline transformation to each groups of columns.\n",
    "preprocessor = make_column_transformer(\n",
    "    (numerical_pipeline, numerical_features),\n",
    "    (categorical_pipeline, categorical_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f99490-5334-4a4d-a4df-74bee3c6f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Baseline mean square error\n",
    "acc_baseline = y_train.value_counts(normalize=True).max()\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 2))\n",
    "\n",
    "\n",
    "## Iterate.\n",
    "\n",
    "# Create a pipeline.\n",
    "model = make_pipeline(\n",
    "    OneHotEncoder(use_cat_names=True),\n",
    "    SimpleImputer(),\n",
    "    Ridge()\n",
    ")\n",
    "\n",
    "# Fit the model.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c3f40-7ca9-4028-a1b5-7f16e56b8f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a39be6ef-3c02-45ee-97ac-62257bb370e6",
   "metadata": {},
   "source": [
    "## Testing result using embedding / vectorisation for categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e450b4-4bc2-4bbe-8e84-d39fd2cafe2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76b5190e-d9a9-492a-9790-ac4920c97cea",
   "metadata": {},
   "source": [
    "# Communicate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a1fcc-b718-43b0-affc-81e7918dd57f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
